#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
@File: txt_to_epub_optimized.py
@Author: Gemini & User
@Date: 2025-10-14
@Version: 17.0 (Optimized Version)
@Description:
    ä¸€ä¸ªä¼˜åŒ–ç‰ˆçš„TXTæ–‡æœ¬æ–‡ä»¶è½¬æ¢ä¸ºEPUBç”µå­ä¹¦çš„è‡ªåŠ¨åŒ–è„šæœ¬ã€‚
    åŒ…å«æ›´å¥½çš„é”™è¯¯å¤„ç†ã€å†…å­˜ç®¡ç†ã€æ ¼å¼ä¼˜åŒ–å’Œé…ç½®ç®¡ç†ã€‚
"""

import os
import re
import logging
import shutil
import time
import requests
from ebooklib import epub
import cn2an
from typing import List, Dict, Any, Optional, Tuple


# ============================ é…ç½®ç±» ============================
class Config:
  """é›†ä¸­ç®¡ç†æ‰€æœ‰é…ç½®é¡¹"""

  def __init__(self):
    # è·¯å¾„é…ç½®
    self.source_folder = os.getenv('TXT_SOURCE_FOLDER') or '/ql/data/my_txts/'
    self.dest_folder = os.getenv('EPUB_DEST_FOLDER') or '/ql/all/'

    # ä¹¦ç±é…ç½®
    self.author = os.getenv('EPUB_AUTHOR') or 'Luna'
    self.publisher = os.getenv('EPUB_PUBLISHER') or 'Auto Generated'

    # åŠŸèƒ½é…ç½®
    self.flatten_output = True
    self.enable_sorting = False
    self.enable_merge_mode = True
    self.delete_source_on_merge = True
    self.backup_before_delete = False

    # æ€§èƒ½é…ç½®
    self.chunk_size = 1024 * 1024  # 1MB
    self.max_retries = 3
    self.retry_delay = 1  # ç§’

    # æ ¼å¼é…ç½®
    self.default_encoding = 'utf-8'
    self.css_style = '''
        body { 
            font-family: "SimSun", "å®‹ä½“", "serif"; 
            line-height: 1.8; 
            margin: 2em; 
            font-size: 16px;
            color: #333;
        }
        h1 { 
            font-size: 1.8em; 
            text-align: center; 
            border-bottom: 2px solid #666; 
            padding-bottom: 0.5em; 
            margin-bottom: 1.5em;
            color: #222;
        }
        p { 
            text-indent: 2em; 
            margin-bottom: 1.2em; 
            text-align: justify;
        }
        .chapter { 
            page-break-before: always;
            margin-top: 2em;
        }
        '''

    # ç« èŠ‚è¯†åˆ«é…ç½®
    self.chinese_numerals = "0-9ã€‡ä¸€äºŒä¸¤ä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶å£¹è´°åè‚†ä¼é™¸æŸ’æŒç–æ‹¾ä½°ä»Ÿ"
    self.volume_regex = re.compile(fr'ç¬¬\s*([{self.chinese_numerals}]+)\s*å·(?!\S)')
    self.chapter_regex = re.compile(fr'ç¬¬\s*([{self.chinese_numerals}]+)\s*[ç« å›èŠ‚é›†](?!\S)')
    self.chapter_regex_line = re.compile(
        fr'^\s*'
        fr'(?:'
        fr'ç¬¬\s*[{self.chinese_numerals}]+\s*[ç« å›èŠ‚é›†å·](?!\S)'
        fr'|'
        fr'[Cc][Hh][Aa][Pp][Tt][Ee][Rr]\s+\d+(?!\S)'
        fr'|'
        fr'å·æœ«æ„Ÿè¨€'
        fr'|'
        fr'^\s*\d+\s*[\.ã€]?\s*[^\.]'  # æ•°å­—å¼€å¤´
        fr')'
        fr'.*$'
        , re.MULTILINE
    )


# ============================ å·¥å…·å‡½æ•° ============================
def setup_logging():
  """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
  log_level = os.getenv('LOG_LEVEL', 'INFO').upper()
  log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
  date_format = '%Y-%m-%d %H:%M:%S'

  logging.basicConfig(
      level=getattr(logging, log_level),
      format=log_format,
      datefmt=date_format,
      handlers=[
        logging.FileHandler('/ql/logs/txt_to_epub.log', encoding='utf-8'),
        logging.StreamHandler()
      ]
  )


def natural_sort_key(s: str) -> List[Any]:
  """è‡ªç„¶æ’åºé”®å‡½æ•°"""
  return [int(text) if text.isdigit() else text.lower()
          for text in re.split(r'(\d+)', s)]


def safe_file_operation(func, *args, max_retries: int = 3, **kwargs):
  """å®‰å…¨çš„æ–‡ä»¶æ“ä½œè£…é¥°å™¨"""
  last_exception = None
  for attempt in range(max_retries):
    try:
      return func(*args, **kwargs)
    except (IOError, OSError) as e:
      last_exception = e
      if attempt < max_retries - 1:
        logging.warning(f"æ–‡ä»¶æ“ä½œå¤±è´¥ï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯•: {e}")
        time.sleep(1)
      else:
        logging.error(f"æ–‡ä»¶æ“ä½œæœ€ç»ˆå¤±è´¥: {e}")
        raise last_exception


def detect_encoding(file_path: str) -> str:
  """ç®€å•æ£€æµ‹æ–‡ä»¶ç¼–ç """
  encodings_to_try = ['utf-8', 'gbk', 'gb2312', 'big5', 'utf-16']

  for enc in encodings_to_try:
    try:
      with open(file_path, 'r', encoding=enc) as f:
        f.read(1024)  # åªè¯»å–å‰1KBè¿›è¡Œæµ‹è¯•
      return enc
    except (UnicodeDecodeError, UnicodeError):
      continue

  return 'utf-8'  # é»˜è®¤å›é€€


def read_file_with_fallback(file_path: str, max_retries: int = 2) -> Optional[str]:
  """å¢å¼ºçš„æ–‡ä»¶è¯»å–ï¼Œæ”¯æŒé‡è¯•å’Œç¼–ç æ£€æµ‹"""
  for attempt in range(max_retries + 1):
    encoding = detect_encoding(file_path)
    try:
      with open(file_path, 'r', encoding=encoding) as f:
        content = f.read()

      if attempt > 0:
        logging.info(f"ç¬¬{attempt + 1}æ¬¡å°è¯•æˆåŠŸï¼Œç¼–ç : {encoding.upper()}")
      else:
        logging.debug(f"æ–‡ä»¶ç¼–ç è¯†åˆ«ä¸º: {encoding.upper()} ({os.path.basename(file_path)})")

      return content

    except Exception as e:
      if attempt == max_retries:
        logging.error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {file_path}ï¼Œæœ€ç»ˆé”™è¯¯: {e}")
      else:
        logging.warning(f"ç¬¬{attempt + 1}æ¬¡è¯»å–å¤±è´¥: {e}")
        time.sleep(1)

  return None


def find_common_book_name(file_list: List[str], source_dir: str) -> str:
  """ä»æ–‡ä»¶ååˆ—è¡¨ä¸­æå–å…±åŒçš„ä¹¦å"""
  if not file_list:
    return os.path.basename(source_dir)

  common_prefix = os.path.commonprefix(file_list)
  cleaned_name = common_prefix.strip(' _-').strip()

  if len(cleaned_name) < 2:
    folder_name = os.path.basename(source_dir)
    logging.warning(f"å…±åŒæ–‡ä»¶åå‰ç¼€ '{cleaned_name}' è¿‡çŸ­æˆ–ä¸ºç©ºï¼Œä½¿ç”¨æ–‡ä»¶å¤¹åç§° '{folder_name}' ä½œä¸ºä¹¦å")
    return folder_name

  logging.info(f"ä»æ–‡ä»¶åä¸­æå–å…±åŒä¹¦å: '{cleaned_name}'")
  return cleaned_name


def send_bark_notification(title: str, body: str):
  """å‘é€Barké€šçŸ¥"""
  bark_url = os.getenv('BARK_PUSH')
  if not bark_url:
    logging.warning("æœªåœ¨ç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ° BARK_PUSH é…ç½®ï¼Œè·³è¿‡é€šçŸ¥")
    return

  try:
    encoded_title = requests.utils.quote(title)
    encoded_body = requests.utils.quote(body)
    url = f"{bark_url.rstrip('/')}/{encoded_title}/{encoded_body}"
    url += "?icon=https://raw.githubusercontent.com/yueshang/pic/main/miao/15.jpg"
    url += "&group=TXTè½¬EPUB"
    url += "&sound=healthnotification"

    logging.info(f"ğŸ“± å‘é€Barké€šçŸ¥: {title}")
    response = requests.get(url, timeout=10)

    if response.status_code == 200:
      logging.info("Bark é€šçŸ¥å‘é€æˆåŠŸ")
    else:
      logging.warning(f"Bark é€šçŸ¥å‘é€å¤±è´¥: {response.status_code}")

  except Exception as e:
    logging.error(f"å‘é€ Bark é€šçŸ¥æ—¶å‘ç”Ÿç½‘ç»œé”™è¯¯: {e}")


def backup_source_files(file_list: List[str], source_dir: str):
  """å¤‡ä»½æºæ–‡ä»¶"""
  config = Config()
  if not config.backup_before_delete:
    return

  backup_dir = os.path.join(source_dir, 'backup')
  os.makedirs(backup_dir, exist_ok=True)
  timestamp = time.strftime("%Y%m%d_%H%M%S")

  for filename in file_list:
    source_path = os.path.join(source_dir, filename)
    backup_path = os.path.join(backup_dir, f"{timestamp}_{filename}")
    safe_file_operation(shutil.copy2, source_path, backup_path)

  logging.info(f"å·²å¤‡ä»½ {len(file_list)} ä¸ªæ–‡ä»¶åˆ° {backup_dir}")


# ============================ æ ¸å¿ƒç±» ============================
class TextParser:
  """æ–‡æœ¬è§£æå™¨ï¼Œè´Ÿè´£ç« èŠ‚è¯†åˆ«å’Œè§£æ"""

  def __init__(self, config: Config):
    self.config = config
    self.chapter_patterns = [
      config.volume_regex,
      config.chapter_regex,
      re.compile(r'^\s*(\d+)\s*[\.ã€]'),  # æ•°å­—å¼€å¤´
      re.compile(r'^\s*[ï¼ˆ\(][^ï¼‰\)]+[ï¼‰\)]'),  # æ‹¬å·å†…å®¹
    ]

  def parse_chapters(self, content: str, force_sort: bool = False) -> List[Dict[str, Any]]:
    """è§£æå†…å®¹ä¸ºç« èŠ‚åˆ—è¡¨"""
    if not content or not content.strip():
      logging.warning("å†…å®¹ä¸ºç©ºï¼Œæ— æ³•è§£æç« èŠ‚")
      return [{'title': 'æ­£æ–‡', 'content': content or '', 'sort_key': (0, 1)}]

    chapter_markers = self._find_all_chapter_markers(content)
    if not chapter_markers:
      return self._handle_no_chapters(content)

    return self._build_chapter_list(content, chapter_markers, force_sort)

  def _find_all_chapter_markers(self, content: str) -> List[re.Match]:
    """æŸ¥æ‰¾æ‰€æœ‰ç« èŠ‚æ ‡è®°"""
    markers = []
    # ä½¿ç”¨ä¸»æ­£åˆ™è¡¨è¾¾å¼
    markers.extend(list(self.config.chapter_regex_line.finditer(content)))

    # æŒ‰ä½ç½®æ’åº
    markers.sort(key=lambda x: x.start())

    # å»é‡ç›¸è¿‘çš„æ ‡è®°
    return self._deduplicate_markers(markers)

  def _deduplicate_markers(self, markers: List[re.Match]) -> List[re.Match]:
    """å»é‡ç›¸è¿‘çš„ç« èŠ‚æ ‡è®°"""
    if not markers:
      return []

    unique_markers = [markers[0]]
    for current in markers[1:]:
      last = unique_markers[-1]
      # å¦‚æœä½ç½®ç›¸è¿‘(50å­—ç¬¦å†…)ï¼Œè®¤ä¸ºæ˜¯åŒä¸€ä¸ªæ ‡è®°
      if current.start() - last.end() > 50:
        unique_markers.append(current)

    return unique_markers

  def _handle_no_chapters(self, content: str) -> List[Dict[str, Any]]:
    """å¤„ç†æ²¡æœ‰ç« èŠ‚æ ‡è®°çš„å†…å®¹"""
    logging.info("æœªæ‰¾åˆ°ç« èŠ‚æ ‡è®°ï¼Œå°†æ•´ä¸ªå†…å®¹ä½œä¸ºå•ä¸€ç« èŠ‚")
    return [{'title': 'æ­£æ–‡', 'content': content.strip(), 'sort_key': (0, 1)}]

  def _build_chapter_list(self, content: str, markers: List[re.Match],
      force_sort: bool) -> List[Dict[str, Any]]:
    """æ„å»ºç« èŠ‚åˆ—è¡¨"""
    chapters = []
    current_volume = 0

    # å¤„ç†å‰è¨€éƒ¨åˆ†
    prologue_content = content[:markers[0].start()].strip()
    if prologue_content:
      chapters.append({'title': 'å‰è¨€', 'content': prologue_content, 'sort_key': (0, 0)})

    # å¤„ç†å„ä¸ªç« èŠ‚
    for i, match in enumerate(markers):
      title = match.group(0).strip()
      content_start = match.end()
      content_end = markers[i + 1].start() if i + 1 < len(markers) else len(content)
      chapter_content = content[content_start:content_end].strip()

      if not chapter_content:
        logging.debug(f"è·³è¿‡ç©ºç« èŠ‚: {title}")
        continue

      # è§£æå·å·å’Œç« èŠ‚å·
      vol_num, chap_num = self._parse_chapter_numbers(title, current_volume)
      if vol_num > 0:
        current_volume = vol_num

      chapters.append({
        'title': title,
        'content': chapter_content,
        'sort_key': (vol_num, chap_num)
      })

    # å»é‡å’Œæ’åº
    return self._finalize_chapters(chapters, force_sort)

  def _parse_chapter_numbers(self, title: str, current_volume: int) -> Tuple[int, float]:
    """è§£æç« èŠ‚çš„å·å·å’Œç« èŠ‚å·"""
    vol_num, chap_num = current_volume, float('inf')

    # æ£€æŸ¥å·å·
    volume_match = self.config.volume_regex.search(title)
    if volume_match:
      try:
        vol_num = cn2an.cn2an(volume_match.group(1), "smart")
        chap_num = 0  # å·æ ‡é¢˜çš„ç« èŠ‚å·ä¸º0
      except Exception as e:
        logging.warning(f"æ— æ³•è½¬æ¢å·å· '{title}': {e}")

    # æ£€æŸ¥ç« èŠ‚å·
    chapter_match = self.config.chapter_regex.search(title)
    if chapter_match:
      try:
        chap_num = cn2an.cn2an(chapter_match.group(1), "smart")
      except Exception as e:
        logging.warning(f"æ— æ³•è½¬æ¢ç« èŠ‚å· '{title}': {e}")

    return vol_num, chap_num

  def _finalize_chapters(self, chapters: List[Dict], force_sort: bool) -> List[Dict]:
    """æœ€ç»ˆå¤„ç†ç« èŠ‚åˆ—è¡¨ï¼ˆå»é‡å’Œæ’åºï¼‰"""
    # å»é‡
    unique_chapters_map = {}
    for chapter in chapters:
      title = chapter['title']
      if title not in unique_chapters_map and chapter['content'].strip():
        unique_chapters_map[title] = chapter

    deduplicated_chapters = list(unique_chapters_map.values())
    logging.info(f"ç« èŠ‚å»é‡: {len(chapters)} -> {len(deduplicated_chapters)}")

    # æ’åº
    if self.config.enable_sorting or force_sort:
      logging.info("æ­£åœ¨è¿›è¡Œåˆ†å±‚æ’åº...")
      sorted_chapters = sorted(deduplicated_chapters, key=lambda x: x['sort_key'])
      logging.info("ç« èŠ‚æ’åºå®Œæˆ")
      return sorted_chapters
    else:
      logging.info("æ’åºå·²å…³é—­")
      return deduplicated_chapters


class EbookGenerator:
  """EPUBç”µå­ä¹¦ç”Ÿæˆå™¨"""

  def __init__(self, config: Config):
    self.config = config

  def create_epub(self, dest_path: str, book_title: str,
      chapters: List[Dict[str, Any]], full_content: str) -> bool:
    """åˆ›å»ºEPUBæ–‡ä»¶"""
    try:
      book = self._create_epub_structure(book_title)
      spine_items = self._add_chapters_to_epub(book, chapters, full_content)
      self._finalize_epub(book, spine_items, dest_path)

      logging.info(f"æˆåŠŸç”ŸæˆEPUB: {dest_path}")
      self._send_success_notification(book_title)
      return True

    except Exception as e:
      logging.error(f"ç”ŸæˆEPUBå¤±è´¥ {dest_path}: {e}")
      self._send_error_notification(book_title, str(e))
      return False

  def _create_epub_structure(self, book_title: str) -> epub.EpubBook:
    """åˆ›å»ºEPUBåŸºç¡€ç»“æ„"""
    book = epub.EpubBook()

    # è®¾ç½®ä¹¦ç±å…ƒæ•°æ®
    book.set_identifier(f"book_{int(time.time())}")
    book.set_title(book_title)
    book.set_language('zh')
    book.add_author(self.config.author)
    book.add_metadata('DC', 'publisher', self.config.publisher)

    # æ·»åŠ CSSæ ·å¼
    style_item = epub.EpubItem(
        uid="style",
        file_name="style/styles.css",
        media_type="text/css",
        content=self.config.css_style
    )
    book.add_item(style_item)

    return book

  def _add_chapters_to_epub(self, book: epub.EpubBook, chapters: List[Dict],
      full_content: str) -> List[epub.EpubHtml]:
    """æ·»åŠ ç« èŠ‚åˆ°EPUB"""
    if not chapters:
      return [self._add_fallback_chapter(book, full_content)]

    spine_items = []
    for i, chap_data in enumerate(chapters, 1):
      chapter = self._create_chapter(chap_data, i)
      if chapter:
        book.add_item(chapter)
        spine_items.append(chapter)
        logging.debug(f"æ·»åŠ ç« èŠ‚: {chap_data['title']}")

    return spine_items

  def _create_chapter(self, chap_data: Dict, index: int) -> Optional[epub.EpubHtml]:
    """åˆ›å»ºå•ä¸ªç« èŠ‚"""
    try:
      chap_title = chap_data['title'][:100]  # é™åˆ¶æ ‡é¢˜é•¿åº¦
      chap_content = self._clean_content(chap_data['content'])

      file_name = f'chapter_{index:04d}.xhtml'
      epub_chap = epub.EpubHtml(
          title=chap_title,
          file_name=file_name,
          lang='zh'
      )

      epub_chap.content = f'''
            <!DOCTYPE html>
            <html>
            <head>
                <title>{chap_title}</title>
                <link rel="stylesheet" type="text/css" href="../style/styles.css"/>
            </head>
            <body>
                <div class="chapter">
                    <h1>{chap_title}</h1>
                    <div>{chap_content}</div>
                </div>
            </body>
            </html>
            '''

      return epub_chap

    except Exception as e:
      logging.error(f"åˆ›å»ºç« èŠ‚å¤±è´¥ {chap_data.get('title', 'æœªçŸ¥')}: {e}")
      return None

  def _add_fallback_chapter(self, book: epub.EpubBook, full_content: str) -> epub.EpubHtml:
    """åˆ›å»ºå›é€€ç« èŠ‚ï¼ˆå½“æ²¡æœ‰è¯†åˆ«åˆ°ç« èŠ‚æ—¶ï¼‰"""
    logging.warning("æœªè¯†åˆ«åˆ°ä»»ä½•æœ‰æ•ˆç« èŠ‚ï¼Œåˆ›å»ºå•ä¸€ç« èŠ‚")
    html_content = self._clean_content(full_content)

    chapter = epub.EpubHtml(
        title='æ­£æ–‡',
        file_name='chapter_0001.xhtml',
        lang='zh'
    )
    chapter.content = f'''
        <!DOCTYPE html>
        <html>
        <head>
            <title>æ­£æ–‡</title>
            <link rel="stylesheet" type="text/css" href="../style/styles.css"/>
        </head>
        <body>
            <div class="chapter">
                <h1>æ­£æ–‡</h1>
                <div>{html_content}</div>
            </div>
        </body>
        </html>
        '''

    book.add_item(chapter)
    return chapter

  def _clean_content(self, content: str) -> str:
    """æ¸…ç†å’Œæ ¼å¼åŒ–å†…å®¹"""
    if not content:
      return "<p>å†…å®¹ä¸ºç©º</p>"

    # åˆ†å‰²æ®µè½å¹¶æ¸…ç†
    paragraphs = [p.strip() for p in content.split('\n') if p.strip()]
    formatted_paragraphs = []

    for para in paragraphs:
      # è·³è¿‡è¿‡çŸ­çš„ç©ºç™½è¡Œ
      if len(para) < 2:
        continue

      # æ™ºèƒ½æ®µè½åˆå¹¶
      if formatted_paragraphs and len(para) < 100:
        # çŸ­æ–‡æœ¬å¯èƒ½æ¥ç»­ä¸Šä¸€æ®µ
        last_index = len(formatted_paragraphs) - 1
        formatted_paragraphs[last_index] = formatted_paragraphs[last_index].replace(
            '</p>', f'{para}</p>'
        )
      else:
        formatted_paragraphs.append(f"<p>{para}</p>")

    return '\n'.join(formatted_paragraphs) if formatted_paragraphs else "<p>æ— æœ‰æ•ˆå†…å®¹</p>"

  def _finalize_epub(self, book: epub.EpubBook, spine_items: List[epub.EpubHtml],
      dest_path: str):
    """æœ€ç»ˆåŒ–EPUBæ–‡ä»¶"""
    # è®¾ç½®ç›®å½•
    book.toc = [epub.Link(item.file_name, item.title, f'chap_{i}')
                for i, item in enumerate(spine_items, 1)]

    # è®¾ç½®é˜…è¯»é¡ºåº
    book.spine = ['nav'] + spine_items

    # æ·»åŠ å¯¼èˆª
    book.add_item(epub.EpubNcx())
    book.add_item(epub.EpubNav())

    # å†™å…¥æ–‡ä»¶
    safe_file_operation(epub.write_epub, dest_path, book, {})

  def _send_success_notification(self, book_title: str):
    """å‘é€æˆåŠŸé€šçŸ¥"""
    send_bark_notification(
        "EPUBè½¬æ¢å®Œæˆ âœ…",
        f"ä¹¦ç±ã€Š{book_title}ã€‹å·²æˆåŠŸç”Ÿæˆ"
    )

  def _send_error_notification(self, book_title: str, error_msg: str):
    """å‘é€é”™è¯¯é€šçŸ¥"""
    send_bark_notification(
        "EPUBè½¬æ¢å¤±è´¥ âŒ",
        f"ä¹¦ç±ã€Š{book_title}ã€‹ç”Ÿæˆå¤±è´¥\né”™è¯¯: {error_msg}"
    )


# ============================ ä»»åŠ¡å¤„ç†å™¨ ============================
class TaskProcessor:
  """ä»»åŠ¡å¤„ç†å™¨ï¼Œè´Ÿè´£åè°ƒæ•´ä¸ªè½¬æ¢æµç¨‹"""

  def __init__(self, config: Config):
    self.config = config
    self.text_parser = TextParser(config)
    self.ebook_generator = EbookGenerator(config)

  def scan_tasks(self) -> List[Dict[str, Any]]:
    """æ‰«ææºæ–‡ä»¶å¤¹ï¼Œå‘ç°å¤„ç†ä»»åŠ¡"""
    tasks_to_process = []

    logging.info("æ­£åœ¨æ‰«æä»»åŠ¡...")
    for dirpath, _, filenames in os.walk(self.config.source_folder):
      txt_files = [f for f in filenames if f.lower().endswith('.txt')]
      if not txt_files:
        continue

      is_root_dir = dirpath.rstrip('/') == self.config.source_folder.rstrip('/')

      # åˆ¤æ–­ä»»åŠ¡ç±»å‹
      if self.config.enable_merge_mode and len(txt_files) > 1 and not is_root_dir:
        tasks_to_process.append({
          'type': 'merge',
          'source_dir': dirpath,
          'files': txt_files
        })
      else:
        for f in txt_files:
          tasks_to_process.append({
            'type': 'single',
            'source_path': os.path.join(dirpath, f)
          })

    logging.info(f"æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(tasks_to_process)} ä¸ªå¤„ç†ä»»åŠ¡")
    return tasks_to_process

  def process_single_file(self, source_path: str, dest_epub_path: str):
    """å¤„ç†å•ä¸ªæ–‡ä»¶ä»»åŠ¡"""
    logging.info(f"å¼€å§‹å¤„ç†å•æ–‡ä»¶ä»»åŠ¡: {source_path}")

    content = read_file_with_fallback(source_path)
    if content is None:
      return

    book_title = os.path.splitext(os.path.basename(source_path))[0]
    processed_chapters = self.text_parser.parse_chapters(content, force_sort=False)

    self.ebook_generator.create_epub(dest_epub_path, book_title, processed_chapters, content)

  def process_merged_files(self, source_dir: str, file_list: List[str],
      master_txt_path: str, dest_epub_path: str):
    """å¤„ç†åˆå¹¶æ–‡ä»¶ä»»åŠ¡"""
    logging.info(f"å¼€å§‹å°±åœ°æ•´åˆæ–‡ä»¶å¤¹: {source_dir}")

    # è¯»å–å¹¶åˆå¹¶æ‰€æœ‰æ–‡ä»¶å†…å®¹
    full_content_list = []
    sorted_files = sorted(file_list, key=natural_sort_key)

    logging.info(f"å°†æŒ‰ä»¥ä¸‹é¡ºåºåˆå¹¶ {len(sorted_files)} ä¸ªæ–‡ä»¶: {sorted_files}")
    for filename in sorted_files:
      file_path = os.path.join(source_dir, filename)
      content = read_file_with_fallback(file_path)
      if content is not None:
        full_content_list.append(content)

    if not full_content_list:
      logging.error("æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡ä»¶å†…å®¹ï¼Œè·³è¿‡æ­¤ä»»åŠ¡")
      return

    merged_content = "\n\n".join(full_content_list)
    book_title = os.path.splitext(os.path.basename(dest_epub_path))[0]

    try:
      # åˆ›å»ºä¸»ç‰ˆæœ¬TXTæ–‡ä»¶
      logging.info(f"æ­£åœ¨åˆ›å»ºä¸»ç‰ˆæœ¬ TXT æ–‡ä»¶: {master_txt_path}")
      safe_file_operation(
          lambda: self._write_master_txt(master_txt_path, merged_content)
      )

      # è§£æç« èŠ‚å¹¶ç”ŸæˆEPUB
      processed_chapters = self.text_parser.parse_chapters(merged_content, force_sort=True)
      epub_success = self.ebook_generator.create_epub(
          dest_epub_path, book_title, processed_chapters, merged_content
      )

      # å¤„ç†æºæ–‡ä»¶
      if os.path.exists(master_txt_path) and epub_success:
        self._handle_source_files_after_merge(source_dir, file_list)
      else:
        logging.error("ä¸»ç‰ˆæœ¬ TXT æˆ– EPUB æ–‡ä»¶åˆ›å»ºå¤±è´¥ï¼Œå·²ä¸­æ­¢æ“ä½œï¼Œæœªåˆ é™¤æºæ–‡ä»¶")

    except Exception as e:
      logging.error(f"åœ¨æ•´åˆå¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œå·²ä¸­æ­¢æ“ä½œ: {e}")

  def _write_master_txt(self, file_path: str, content: str):
    """å†™å…¥ä¸»ç‰ˆæœ¬TXTæ–‡ä»¶"""
    with open(file_path, 'w', encoding='utf-8') as f:
      f.write(content)

  def _handle_source_files_after_merge(self, source_dir: str, file_list: List[str]):
    """åˆå¹¶æˆåŠŸåå¤„ç†æºæ–‡ä»¶"""
    if self.config.delete_source_on_merge:
      if self.config.backup_before_delete:
        backup_source_files(file_list, source_dir)

      logging.info(f"æ•´åˆæˆåŠŸï¼Œæ­£åœ¨åˆ é™¤åŸå§‹ {len(file_list)} ä¸ªæºæ–‡ä»¶...")
      for filename in file_list:
        file_path = os.path.join(source_dir, filename)
        safe_file_operation(os.remove, file_path)

      logging.info("åŸå§‹æºæ–‡ä»¶å·²åˆ é™¤")
    else:
      logging.info("æ•´åˆæˆåŠŸï¼Œæ ¹æ®é…ç½®ä¿ç•™åŸå§‹æºæ–‡ä»¶")

  def validate_directories(self):
    """éªŒè¯ç›®å½•æ˜¯å¦å­˜åœ¨"""
    if not os.path.isdir(self.config.source_folder):
      raise FileNotFoundError(f"æºæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {self.config.source_folder}")

    if not os.path.isdir(self.config.dest_folder):
      logging.info(f"ç›®æ ‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º: {self.config.dest_folder}")
      safe_file_operation(os.makedirs, self.config.dest_folder, exist_ok=True)


# ============================ ä¸»å‡½æ•° ============================
def main():
  """ä¸»å‡½æ•°"""
  setup_logging()

  try:
    logging.info("ğŸš€ TXTè½¬EPUBä»»åŠ¡å¼€å§‹ (ä¼˜åŒ–ç‰ˆ v17.0)")

    # åˆå§‹åŒ–é…ç½®å’Œå¤„ç†å™¨
    config = Config()
    processor = TaskProcessor(config)

    # éªŒè¯ç›®å½•
    processor.validate_directories()
    logging.info(f"æºæ–‡ä»¶å¤¹: {config.source_folder}, ç›®æ ‡æ–‡ä»¶å¤¹: {config.dest_folder}")

    # æ‰«æå’Œå¤„ç†ä»»åŠ¡
    tasks = processor.scan_tasks()
    if not tasks:
      logging.info("ğŸ“­ æœªæ‰¾åˆ°å¾…å¤„ç†ä»»åŠ¡")
      return

    # å¤„ç†æ¯ä¸ªä»»åŠ¡
    success_count = 0
    for task in tasks:
      try:
        if task['type'] == 'merge':
          success = _process_merge_task(processor, task, config)
        else:
          success = _process_single_task(processor, task, config)

        if success:
          success_count += 1

      except Exception as e:
        logging.error(f"å¤„ç†ä»»åŠ¡å¤±è´¥: {task}ï¼Œé”™è¯¯: {e}")
      finally:
        logging.info("-" * 50)

    # æ€»ç»“æŠ¥å‘Š
    logging.info(f"âœ… ä»»åŠ¡å¤„ç†å®Œæˆ: {success_count}/{len(tasks)} æˆåŠŸ")
    send_bark_notification(
        "TXTè½¬EPUBä»»åŠ¡å®Œæˆ",
        f"å¤„ç†äº† {len(tasks)} ä¸ªä»»åŠ¡ï¼ŒæˆåŠŸ {success_count} ä¸ª"
    )

  except Exception as e:
    logging.error(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
    send_bark_notification("TXTè½¬EPUBå¤±è´¥", f"é”™è¯¯: {str(e)}")
    raise


def _process_merge_task(processor: TaskProcessor, task: Dict, config: Config) -> bool:
  """å¤„ç†åˆå¹¶ä»»åŠ¡"""
  source_dir = task['source_dir']
  book_name = os.path.basename(source_dir)
  dest_epub_path = os.path.join(config.dest_folder, f"{book_name}.epub")
  master_txt_path = os.path.join(source_dir, f"{book_name}.txt")

  # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
  if os.path.exists(dest_epub_path) or os.path.exists(master_txt_path):
    logging.info(f"åˆå¹¶ä»»åŠ¡ '{source_dir}' å¯¹åº”çš„æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡")
    return False

  processor.process_merged_files(
      source_dir, task['files'], master_txt_path, dest_epub_path
  )
  return True


def _process_single_task(processor: TaskProcessor, task: Dict, config: Config) -> bool:
  """å¤„ç†å•ä¸ªæ–‡ä»¶ä»»åŠ¡"""
  source_path = task['source_path']
  book_name = os.path.splitext(os.path.basename(source_path))[0]
  dest_epub_path = os.path.join(config.dest_folder, f"{book_name}.epub")

  # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
  if os.path.exists(dest_epub_path):
    source_mtime = os.path.getmtime(source_path)
    dest_mtime = os.path.getmtime(dest_epub_path)
    if source_mtime <= dest_mtime:
      logging.info(f"æ–‡ä»¶ '{source_path}' å¯¹åº”çš„EPUBå·²å­˜åœ¨ä¸”æœªæ›´æ–°ï¼Œè·³è¿‡")
      return False

  processor.process_single_file(source_path, dest_epub_path)
  return True


if __name__ == '__main__':
  main()